{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOhDWmovlVkEddBQ1uP+0q"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22340eab",
        "outputId": "11e70acf-c53e-4e9c-f70b-8cdab839e61c"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df=pd.read_csv('processed_stock_sentiment_data.csv',parse_dates=['Date'])\n",
        "\n",
        "print(\"Loaded DataFrame head:\")\n",
        "print(df.head())\n",
        "print(\"\\nLoaded DataFrame info:\")\n",
        "df.info()\n",
        "print(\"\\nLoaded DataFrame missing values:\")\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded DataFrame head:\n",
            "        Date Ticker      Open      High       Low     Close    Volume  \\\n",
            "0 2020-01-01   AAPL -1.199541 -1.208103 -1.207332 -1.209787  1.084094   \n",
            "1 2020-01-01   AMZN  0.954349  0.952376  0.947163  0.943253 -1.119577   \n",
            "2 2020-01-01  GOOGL -0.911275 -0.917211 -0.902913 -0.909482 -1.264718   \n",
            "3 2020-01-01   MSFT  1.185268  1.186715  1.192973  1.192739 -0.458786   \n",
            "4 2020-01-02   AAPL -1.205103 -1.213428 -1.218217 -1.220057  0.137586   \n",
            "\n",
            "   Sentiment_Score  Tweet_Count  Daily_Return  ...  Tweet_Count_Lag_3  \\\n",
            "0         0.582662     1.414376      0.000000  ...                0.0   \n",
            "1         0.026002    -0.924491      0.000000  ...                0.0   \n",
            "2         0.236540    -0.549911      0.000000  ...                0.0   \n",
            "3         2.181534     1.932654      0.000000  ...                0.0   \n",
            "4         1.288644     0.351965      0.008489  ...                0.0   \n",
            "\n",
            "   Tweet_Count_Lag_5  Sentiment_MA_7  Tweet_Count_MA_7  Close_SMA_7  \\\n",
            "0                0.0        0.582662          1.414376    -1.209787   \n",
            "1                0.0        0.026002         -0.924491     0.943253   \n",
            "2                0.0        0.236540         -0.549911    -0.909482   \n",
            "3                0.0        2.181534          1.932654     1.192739   \n",
            "4                0.0        0.935653          0.883171    -1.214922   \n",
            "\n",
            "   Close_SMA_30  Volatility_7D  Next_Day_Return  Median_Next_Day_Return  \\\n",
            "0     -1.209787       0.000000         0.008489                0.008482   \n",
            "1      0.943253       0.000000         0.024739                0.008482   \n",
            "2     -0.909482       0.000000        -0.015358                0.008482   \n",
            "3      1.192739       0.000000         0.008474                0.008482   \n",
            "4     -1.214922       0.006003        -0.020198               -0.010115   \n",
            "\n",
            "   Outperform_Median  \n",
            "0                  1  \n",
            "1                  1  \n",
            "2                  0  \n",
            "3                  0  \n",
            "4                  0  \n",
            "\n",
            "[5 rows x 30 columns]\n",
            "\n",
            "Loaded DataFrame info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4000 entries, 0 to 3999\n",
            "Data columns (total 30 columns):\n",
            " #   Column                  Non-Null Count  Dtype         \n",
            "---  ------                  --------------  -----         \n",
            " 0   Date                    4000 non-null   datetime64[ns]\n",
            " 1   Ticker                  4000 non-null   object        \n",
            " 2   Open                    4000 non-null   float64       \n",
            " 3   High                    4000 non-null   float64       \n",
            " 4   Low                     4000 non-null   float64       \n",
            " 5   Close                   4000 non-null   float64       \n",
            " 6   Volume                  4000 non-null   float64       \n",
            " 7   Sentiment_Score         4000 non-null   float64       \n",
            " 8   Tweet_Count             4000 non-null   float64       \n",
            " 9   Daily_Return            4000 non-null   float64       \n",
            " 10  Close_Lag_1             4000 non-null   float64       \n",
            " 11  Close_Lag_3             4000 non-null   float64       \n",
            " 12  Close_Lag_5             4000 non-null   float64       \n",
            " 13  Volume_Lag_1            4000 non-null   float64       \n",
            " 14  Volume_Lag_3            4000 non-null   float64       \n",
            " 15  Volume_Lag_5            4000 non-null   float64       \n",
            " 16  Sentiment_Score_Lag_1   4000 non-null   float64       \n",
            " 17  Sentiment_Score_Lag_3   4000 non-null   float64       \n",
            " 18  Sentiment_Score_Lag_5   4000 non-null   float64       \n",
            " 19  Tweet_Count_Lag_1       4000 non-null   float64       \n",
            " 20  Tweet_Count_Lag_3       4000 non-null   float64       \n",
            " 21  Tweet_Count_Lag_5       4000 non-null   float64       \n",
            " 22  Sentiment_MA_7          4000 non-null   float64       \n",
            " 23  Tweet_Count_MA_7        4000 non-null   float64       \n",
            " 24  Close_SMA_7             4000 non-null   float64       \n",
            " 25  Close_SMA_30            4000 non-null   float64       \n",
            " 26  Volatility_7D           4000 non-null   float64       \n",
            " 27  Next_Day_Return         4000 non-null   float64       \n",
            " 28  Median_Next_Day_Return  4000 non-null   float64       \n",
            " 29  Outperform_Median       4000 non-null   int64         \n",
            "dtypes: datetime64[ns](1), float64(27), int64(1), object(1)\n",
            "memory usage: 937.6+ KB\n",
            "\n",
            "Loaded DataFrame missing values:\n",
            "Date                      0\n",
            "Ticker                    0\n",
            "Open                      0\n",
            "High                      0\n",
            "Low                       0\n",
            "Close                     0\n",
            "Volume                    0\n",
            "Sentiment_Score           0\n",
            "Tweet_Count               0\n",
            "Daily_Return              0\n",
            "Close_Lag_1               0\n",
            "Close_Lag_3               0\n",
            "Close_Lag_5               0\n",
            "Volume_Lag_1              0\n",
            "Volume_Lag_3              0\n",
            "Volume_Lag_5              0\n",
            "Sentiment_Score_Lag_1     0\n",
            "Sentiment_Score_Lag_3     0\n",
            "Sentiment_Score_Lag_5     0\n",
            "Tweet_Count_Lag_1         0\n",
            "Tweet_Count_Lag_3         0\n",
            "Tweet_Count_Lag_5         0\n",
            "Sentiment_MA_7            0\n",
            "Tweet_Count_MA_7          0\n",
            "Close_SMA_7               0\n",
            "Close_SMA_30              0\n",
            "Volatility_7D             0\n",
            "Next_Day_Return           0\n",
            "Median_Next_Day_Return    0\n",
            "Outperform_Median         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7d0aeb8",
        "outputId": "30ae885c-26e2-4f39-b94c-5b8fc10052ed"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1. Define the feature matrix X\n",
        "# Exclude 'Date', 'Ticker', 'Daily_Return', 'Next_Day_Return', 'Median_Next_Day_Return', and 'Outperform_Median'\n",
        "features_to_exclude = ['Date', 'Ticker', 'Daily_Return', 'Next_Day_Return', 'Median_Next_Day_Return', 'Outperform_Median']\n",
        "X = df.drop(columns=features_to_exclude)\n",
        "\n",
        "# 2. Define the target vector y\n",
        "y = df['Outperform_Median']\n",
        "\n",
        "# 3. Initialize a StandardScaler object\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# 4. Apply the StandardScaler to the feature matrix X\n",
        "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns, index=X.index)\n",
        "\n",
        "# 5. Create a time-based train-test split\n",
        "split_date = '2022-01-01'\n",
        "\n",
        "X_train = X[df['Date'] < split_date]\n",
        "X_test = X[df['Date'] >= split_date]\n",
        "y_train = y[df['Date'] < split_date]\n",
        "y_test = y[df['Date'] >= split_date]\n",
        "\n",
        "print(f\"Original feature matrix X shape: {X.shape}\")\n",
        "print(f\"Original target vector y shape: {y.shape}\")\n",
        "print(f\"Training features shape: {X_train.shape}\")\n",
        "print(f\"Testing features shape: {X_test.shape}\")\n",
        "print(f\"Training target shape: {y_train.shape}\")\n",
        "print(f\"Testing target shape: {y_test.shape}\")\n",
        "\n",
        "print(\"\\nScaled X head:\")\n",
        "print(X.head())"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original feature matrix X shape: (4000, 24)\n",
            "Original target vector y shape: (4000,)\n",
            "Training features shape: (2924, 24)\n",
            "Testing features shape: (1076, 24)\n",
            "Training target shape: (2924,)\n",
            "Testing target shape: (1076,)\n",
            "\n",
            "Scaled X head:\n",
            "       Open      High       Low     Close    Volume  Sentiment_Score  \\\n",
            "0 -1.199541 -1.208103 -1.207332 -1.209787  1.084094         0.582662   \n",
            "1  0.954349  0.952376  0.947163  0.943253 -1.119577         0.026002   \n",
            "2 -0.911275 -0.917211 -0.902913 -0.909482 -1.264718         0.236540   \n",
            "3  1.185268  1.186715  1.192973  1.192739 -0.458786         2.181534   \n",
            "4 -1.205103 -1.213428 -1.218217 -1.220057  0.137586         1.288644   \n",
            "\n",
            "   Tweet_Count  Close_Lag_1  Close_Lag_3  Close_Lag_5  ...  \\\n",
            "0     1.414376    -0.000140    -0.000419    -0.000697  ...   \n",
            "1    -0.924491    -0.000140    -0.000419    -0.000697  ...   \n",
            "2    -0.549911    -0.000140    -0.000419    -0.000697  ...   \n",
            "3     1.932654    -0.000140    -0.000419    -0.000697  ...   \n",
            "4     0.351965    -1.210425    -0.000419    -0.000697  ...   \n",
            "\n",
            "   Sentiment_Score_Lag_3  Sentiment_Score_Lag_5  Tweet_Count_Lag_1  \\\n",
            "0               0.000078                0.00013          -0.000925   \n",
            "1               0.000078                0.00013          -0.000925   \n",
            "2               0.000078                0.00013          -0.000925   \n",
            "3               0.000078                0.00013          -0.000925   \n",
            "4               0.000078                0.00013           1.414056   \n",
            "\n",
            "   Tweet_Count_Lag_3  Tweet_Count_Lag_5  Sentiment_MA_7  Tweet_Count_MA_7  \\\n",
            "0          -0.002777          -0.004632        1.575162          1.777957   \n",
            "1          -0.002777          -0.004632        0.067528         -1.170576   \n",
            "2          -0.002777          -0.004632        0.637741         -0.698356   \n",
            "3          -0.002777          -0.004632        5.905473          2.431334   \n",
            "4          -0.002777          -0.004632        2.531186          1.108284   \n",
            "\n",
            "   Close_SMA_7  Close_SMA_30  Volatility_7D  \n",
            "0    -1.209709     -1.209025      -3.364068  \n",
            "1     0.942408      0.938936      -3.364068  \n",
            "2    -0.909533     -0.909429      -3.364068  \n",
            "3     1.191788      1.187834      -3.364068  \n",
            "4    -1.214842     -1.214148      -2.089060  \n",
            "\n",
            "[5 rows x 24 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fedf4f1",
        "outputId": "3b24ea2f-0c93-45d8-81c7-47b201d0805d"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Initialize a LogisticRegression model\n",
        "model = LogisticRegression(random_state=42, solver='liblinear') # Added random_state for reproducibility and solver for convergence\n",
        "\n",
        "# Train the LogisticRegression model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Logistic Regression model trained successfully.\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression model trained successfully.\n"
          ]
        }
      ]
    }
  ]
}